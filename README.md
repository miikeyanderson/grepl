# Greppy

Semantic code search CLI using ChromaDB + Ollama. Integrates with Claude Code via Skills.

**No Docker required.** Everything runs locally.

![Greppy Demo](experiment.gif)

*Video sped up 5x. With Greppy: 37s | Without Greppy: 1m 20s*

## Architecture

```
Claude Code → Skill → greppy CLI → ChromaDB + Ollama
                      (Python)     (embedded)  (local)
```

## Quick Start

### 1. Install Ollama

```bash
# macOS
brew install ollama

# Start Ollama (keep running in background)
ollama serve

# Pull embedding model
ollama pull nomic-embed-text
```

### 2. Install Greppy

**Option A: Via Homebrew (recommended)**
```bash
brew tap dyoburon/greppy
brew install greppy
```

**Option B: Via pip**
```bash
pip install -e /path/to/greppy
```

**Option C: Via pipx**
```bash
pipx install /path/to/greppy
```

### 3. Verify Installation

```bash
greppy --help
```

### 4. Index Your Codebase

```bash
cd /path/to/your/project
greppy index .
```

### 5. Search!

```bash
greppy search "authentication logic"
greppy search "error handling" -n 20
greppy exact "TODO"  # Exact pattern match
greppy read src/auth.py:45  # Read context around line 45
```

## Usage

### Index a Codebase
```bash
greppy index .
greppy index /path/to/project
greppy index . --force  # Reindex
```

### Semantic Search
```bash
greppy search "authentication logic"
greppy search "how errors are handled" -n 20
greppy search "database queries" -p /path/to/project
```

### Exact Pattern Match
```bash
greppy exact "TODO"
greppy exact "def process_payment"
greppy exact "import React" -p ./src
```

### Read Files
```bash
greppy read src/auth.py              # Read first 50 lines
greppy read src/auth.py:45           # Read ~50 lines centered on line 45
greppy read src/auth.py:30-80        # Read lines 30-80
greppy read src/auth.py -c 100       # Read 100 lines of context
```

### Check Status
```bash
greppy status
greppy status /path/to/project
```

### Clear Index
```bash
greppy clear
```

## Claude Code Integration

### Setup

Create a `.claude` folder in your project with these files:

#### 1. `.claude/settings.json`

```json
{
  "permissions": {
    "allow": [
      "Bash(greppy:*)"
    ],
    "deny": [
      "Glob",
      "Grep",
      "Read",
      "Task(Explore)"
    ]
  }
}
```

This blocks Claude's native search/read tools, forcing it to use greppy for all code operations.

#### 2. `.claude/skills/code-search/SKILL.md`

```markdown
---
name: code-search
description: Semantic code search for finding code by meaning. Use when searching for concepts, logic, patterns, or asking "where is X handled" or "find code that does Y".
allowed-tools: Bash(greppy:*)
---

# Code Search Skill

## When to Use This Skill

Use `greppy search` for:
- Finding code by concept ("authentication logic", "error handling")
- Exploring unfamiliar codebases
- Searching by intent, not exact text

Use `greppy exact` for:
- Specific strings, function names, imports
- TODOs, FIXMEs, exact patterns

Use `greppy read` for:
- Reading file contents after finding a match
- Viewing context around a specific line

## Commands

### Semantic Search
\`\`\`bash
greppy search "your query" -n 10
\`\`\`

### Exact Match
\`\`\`bash
greppy exact "pattern"
\`\`\`

### Read File
\`\`\`bash
greppy read file.py:45    # Context around line 45
greppy read file.py:30-80 # Lines 30-80
\`\`\`
```

#### 3. Add to `CLAUDE.md` (recommended)

Add this to your project's `CLAUDE.md` file:

```markdown
## Code Search - IMPORTANT

**Always use `greppy` for all code operations in this codebase.** Do NOT use Glob, Grep, Read, or the Explore agent.

\`\`\`bash
# Semantic search (find by meaning/concept)
greppy search "authentication logic"

# Exact pattern match
greppy exact "def process_payment"

# Read file contents
greppy read src/auth.py:45
\`\`\`

The index is already built. Just run the search commands directly.
```

### Quick Setup (Copy Files)

Or simply copy the `.claude` folder from greppy:

```bash
cp -r /path/to/greppy/.claude /path/to/your/project/
```

Then restart Claude Code to load the settings.

### How It Works

**Layer 1: Permissions (Enforcement)** - Native tools are denied in settings.json:
```
Claude tries Grep/Glob/Read → DENIED → Must use greppy instead
```

**Layer 2: Skill (Guidance)** - The skill teaches Claude when and how to use greppy:
```
"find authentication logic" → Skill matches → greppy search "authentication"
```

**Layer 3: CLAUDE.md (Instruction)** - Explicit instruction to use greppy for all code operations

## Data Storage

Greppy stores indexes in `~/.greppy/chroma/`. Each project gets its own collection.

## Keeping Ollama Running (Recommended)

Ollama stops when your terminal closes or Mac sleeps. Here's how to keep it running automatically.

### Option 1: Hammerspoon (macOS)

If you use [Hammerspoon](https://www.hammerspoon.org/), add this to your `~/.hammerspoon/init.lua`:

```lua
-- Ollama Keepalive
-- Ensures Ollama is always running for greppy

local ollamaPath = "/opt/homebrew/bin/ollama"  -- Apple Silicon
-- local ollamaPath = "/usr/local/bin/ollama"  -- Intel Mac

local function isOllamaRunning()
    local output, status = hs.execute("pgrep -x ollama")
    return status
end

local function startOllama()
    if not isOllamaRunning() then
        hs.task.new(ollamaPath, nil, {"serve"}):start()
    end
end

-- Start on launch
startOllama()

-- Check every 5 minutes
hs.timer.doEvery(300, startOllama)

-- Restart after wake from sleep
hs.caffeinate.watcher.new(function(event)
    if event == hs.caffeinate.watcher.systemDidWake then
        hs.timer.doAfter(2, startOllama)
    end
end):start()
```

Then reload Hammerspoon: `hs -c "hs.reload()"`

### Option 2: LaunchAgent (macOS)

Create a LaunchAgent that auto-starts Ollama on login:

```bash
cat > ~/Library/LaunchAgents/com.ollama.serve.plist << 'EOF'
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
    <key>Label</key>
    <string>com.ollama.serve</string>
    <key>ProgramArguments</key>
    <array>
        <string>/opt/homebrew/bin/ollama</string>
        <string>serve</string>
    </array>
    <key>RunAtLoad</key>
    <true/>
    <key>KeepAlive</key>
    <true/>
</dict>
</plist>
EOF

launchctl load ~/Library/LaunchAgents/com.ollama.serve.plist
```

### Option 3: Ollama Desktop App

Download from [ollama.com](https://ollama.com). The desktop app runs as a menu bar item and auto-starts on login.

## Troubleshooting

| Issue | Fix |
|-------|-----|
| Ollama not running | `ollama serve` (or see "Keeping Ollama Running" above) |
| Model not found | `ollama pull nomic-embed-text` |
| greppy not found | `brew tap dyoburon/greppy && brew install greppy` |
| Index missing | `greppy index .` |
| Skill not activating | Restart Claude Code |

## Cost

| Component | Cost |
|-----------|------|
| ChromaDB | $0 (embedded, local) |
| Ollama | $0 (local) |
| **Total** | **$0** |

## Tech Stack

- **ChromaDB**: Embedded vector database (no server)
- **Ollama**: Local embeddings via nomic-embed-text
- **Python**: Simple, portable CLI

## Experiments

Benchmarks comparing Greppy vs standard Claude Code exploration are in the `experiments/` folder.

### Chart Generation Search (2026-01-07)

Task: Find all code related to chart generation logic in the datafeeds project.

| Metric | With Greppy | Without Greppy |
|--------|-------------|----------------|
| Duration | 1m 16s | 2m 26s |
| Tokens | 400 | 15,309 |
| Cost | $0.02 | $0.44 |

**Result: Greppy was 2x faster and 22x cheaper.**

### Why Is It So Much Cheaper?

**Without Greppy**, the LLM has to *read actual file contents* to understand what's in them. It issues Glob/Grep commands, reads files, processes them, searches more, reads more files. All that file content goes into the context window, burning through tokens. The LLM is essentially reading your entire codebase to find what it's looking for.

**With Greppy**, Ollama does the semantic search *locally* (free, no tokens). ChromaDB returns relevant file paths and snippets. The LLM only sees the search results—a few lines per match—not entire files.
